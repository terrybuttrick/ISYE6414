{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11417870,"sourceType":"datasetVersion","datasetId":7150917}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, roc_auc_score, roc_curve\nfrom sklearn.feature_selection import SelectFromModel, RFE\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import StratifiedKFold, cross_val_score\nfrom sklearn.pipeline import Pipeline\nimport warnings\nimport time\nwarnings.filterwarnings('ignore')\nprint(\"# Housing Price Growth Prediction Model\")\nprint(\"## Approach #4: Improved Logistic Regression Model\")\ndf = pd.read_csv(\"everything/everything.csv\")\ndf['date'] = pd.to_datetime(df['date'], errors='coerce')\ndf['RegionName'] = df['RegionName'].astype(str)\ndf = df[(df['date'].dt.year >= 2007) & (df['date'].dt.year <= 2023)].copy()\ndef safe_temporal_operations(group):\n    for lag in [1, 3, 6]:\n        group[f'ZHVI_lag{lag}'] = group['ZHVI'].shift(lag)\n    group['pct_change_1m'] = group['ZHVI'].pct_change(periods=1)\n    group['pct_change_3m'] = group['ZHVI'].pct_change(periods=3)\n    group['pct_change_6m'] = group['ZHVI'].pct_change(periods=6)\n    group['ZHVI_3m_avg'] = group['ZHVI'].shift(1).rolling(window=3).mean()\n    group['ZHVI_6m_avg'] = group['ZHVI'].shift(1).rolling(window=6).mean()\n    group['ZHVI_3m_vol'] = group['ZHVI'].shift(1).rolling(window=3).std()\n    group['ZHVI_6m_vol'] = group['ZHVI'].shift(1).rolling(window=6).std()\n    group['ROC_3m'] = group['ZHVI'].pct_change(3) / 3  # Average monthly change over 3 months\n    group['ROC_6m'] = group['ZHVI'].pct_change(6) / 6  # Average monthly change over 6 months\n    group['target_pct_change'] = group['ZHVI'].pct_change(periods=1).shift(-1)\n    group['month'] = group['date'].dt.month\n    group['quarter'] = group['date'].dt.quarter\n    \n    return group\n    \n  \nprint(\"Creating temporal features...\")\ndf = df.groupby('RegionName', group_keys=False).apply(safe_temporal_operations)\ndf = df.dropna(subset=['target_pct_change'])\ndf['target_binary'] = (df['target_pct_change'] > 0).astype(int)\ntrain_end = pd.to_datetime('2022-11-01')\nval_end   = pd.to_datetime('2023-05-01')\ntest_end  = pd.to_datetime('2023-11-01')\n\ndf_train = df[df['date'] < train_end].copy()\ndf_val   = df[(df['date'] >= train_end) & (df['date'] < val_end)].copy()\ndf_test  = df[(df['date'] >= val_end) & (df['date'] < test_end)].copy()\n\nprint(f\"Train set: {df_train.shape[0]} rows, from {df_train['date'].min().date()} to {df_train['date'].max().date()}\")\nprint(f\"Validation set: {df_val.shape[0]} rows, from {df_val['date'].min().date()} to {df_val['date'].max().date()}\")\nprint(f\"Test set: {df_test.shape[0]} rows, from {df_test['date'].min().date()} to {df_test['date'].max().date()}\")\ncore_features = [\n    'ZHVI_lag1', 'ZHVI_lag3', 'ZHVI_lag6',\n    'pct_change_1m', 'pct_change_3m', 'pct_change_6m',\n    'ZHVI_3m_avg', 'ZHVI_6m_avg',\n    'ZHVI_3m_vol', 'ZHVI_6m_vol',\n    'ROC_3m', 'ROC_6m'\n]\nmacro_features = [\n    'Mortgage_rate', 'CPI', 'CPI_Rent', 'Unemp_rate', 'NASDAQ', \n    'disposable_income', 'Personal_consumption_expenditure', 'personal_savings'\n]\n\nlocation_features = ['SizeRank', 'Percent___of_State_Area_s_Population', 'Percent___of_Labor_Force_Unemployed_in_State_Area']\n\ntime_features = ['Year', 'month', 'quarter']\nall_features = core_features + macro_features + location_features + time_features\navailable_features = [col for col in all_features if col in df_train.columns]\nprint(f\"\\nAvailable features: {len(available_features)} out of {len(all_features)}\")\ndf_train['Year'] = df_train['date'].dt.year\ndf_val['Year'] = df_val['date'].dt.year\ndf_test['Year'] = df_test['date'].dt.year\nif 'month' not in df_train.columns:\n    df_train['month'] = df_train['date'].dt.month\n    df_val['month'] = df_val['date'].dt.month\n    df_test['month'] = df_test['date'].dt.month\n\nif 'quarter' not in df_train.columns:\n    df_train['quarter'] = df_train['date'].dt.quarter\n    df_val['quarter'] = df_val['date'].dt.quarter\n    df_test['quarter'] = df_test['date'].dt.quarter\n\ndef preprocess_data(df, features, train_mode=False):\n    processed_df = df.copy()\n    cat_features = ['RegionName']\n    for cat in cat_features:\n        if cat in processed_df.columns:\n            if train_mode:\n                dummies = pd.get_dummies(processed_df[cat], prefix=cat, drop_first=True)\n                global CATEGORIES\n                CATEGORIES = {cat: list(dummies.columns)}\n            else:\n                dummies = pd.get_dummies(processed_df[cat], prefix=cat)\n                for col in CATEGORIES[cat]:\n                    if col not in dummies.columns:\n                        dummies[col] = 0\n                dummies = dummies[CATEGORIES[cat]]\n            \n            processed_df = pd.concat([processed_df, dummies], axis=1)\n    if train_mode:\n        season_dummies = pd.get_dummies(processed_df['month'].apply(lambda x: (x%12)//3 + 1), prefix='season', drop_first=True)\n        global SEASON_COLUMNS\n        SEASON_COLUMNS = list(season_dummies.columns)\n    else:\n        season_dummies = pd.get_dummies(processed_df['month'].apply(lambda x: (x%12)//3 + 1), prefix='season')\n        for col in SEASON_COLUMNS:\n            if col not in season_dummies.columns:\n                season_dummies[col] = 0\n        season_dummies = season_dummies[SEASON_COLUMNS]\n    \n    processed_df = pd.concat([processed_df, season_dummies], axis=1)\n    dummy_features = []\n    if 'RegionName' in cat_features:\n        dummy_features.extend(CATEGORIES['RegionName'])\n    dummy_features.extend(SEASON_COLUMNS)\n    features_to_use = [f for f in features if f in processed_df.columns] + dummy_features\n    X = processed_df[features_to_use]\n    y = processed_df['target_binary'] if 'target_binary' in processed_df.columns else None\n    \n    return X, y\n\nprint(\"\\nPerforming feature selection...\")\nX_train_raw, y_train = preprocess_data(df_train, available_features, train_mode=True)\nimputer = SimpleImputer(strategy='median')\nX_train_imputed = imputer.fit_transform(X_train_raw)\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train_imputed)\nrf_selector = RandomForestClassifier(n_estimators=100, random_state=42)\nrf_selector.fit(X_train_scaled, y_train)\nimportances = rf_selector.feature_importances_\nindices = np.argsort(importances)[::-1]\nprint(\"\\nTop 15 most important features:\")\nfor i in range(min(15, len(indices))):\n    print(f\"{X_train_raw.columns[indices[i]]}: {importances[indices[i]]:.4f}\")\n\nselector = SelectFromModel(rf_selector, prefit=True, threshold='mean')\nX_train_selected = selector.transform(X_train_scaled)\nselected_indices = selector.get_support()\nselected_features = X_train_raw.columns[selected_indices].tolist()\n\nprint(f\"\\nSelected {len(selected_features)} features from {X_train_raw.shape[1]} total features\")\nprint(\"Selected features:\", selected_features)\nX_val_raw, y_val = preprocess_data(df_val, available_features, train_mode=False)\nX_val_imputed = imputer.transform(X_val_raw)\nX_val_scaled = scaler.transform(X_val_imputed)\nX_val_selected = selector.transform(X_val_scaled)\nX_test_raw, y_test = preprocess_data(df_test, available_features, train_mode=False)\nX_test_imputed = imputer.transform(X_test_raw)\nX_test_scaled = scaler.transform(X_test_imputed)\nX_test_selected = selector.transform(X_test_scaled)\n\nprint(\"\\nTraining logistic regression with cross-validation...\")\nC_values = [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]\nbest_C = None\nbest_score = -np.inf\nfor C in C_values:\n    model = LogisticRegression(C=C, max_iter=1000, solver='liblinear', random_state=42)\n    cv_scores = cross_val_score(model, X_train_selected, y_train, cv=5, scoring='roc_auc')\n    mean_score = np.mean(cv_scores)\n    print(f\"C={C}: Mean ROC-AUC: {mean_score:.4f}\")\n    \n    if mean_score > best_score:\n        best_score = mean_score\n        best_C = C\n\nprint(f\"Best C value: {best_C} with ROC-AUC: {best_score:.4f}\")\nfinal_model = LogisticRegression(C=best_C, max_iter=1000, solver='liblinear', random_state=42)\nfinal_model.fit(X_train_selected, y_train)\ncoefficients = pd.DataFrame({\n    'Feature': [X_train_raw.columns[i] for i in range(len(X_train_raw.columns)) if selected_indices[i]],\n    'Coefficient': final_model.coef_[0]\n})\ncoefficients = coefficients.sort_values('Coefficient', ascending=False)\n\nprint(\"\\nTop positive coefficients:\")\nprint(coefficients.head(10))\nprint(\"\\nTop negative coefficients:\")\nprint(coefficients.tail(10))\ndef evaluate_model(model, X, y, set_name):\n    y_prob = model.predict_proba(X)[:, 1]\n    y_pred = model.predict(X)\n    print(f\"\\n{set_name} Performance:\")\n    print(classification_report(y, y_pred))\n    roc_auc = roc_auc_score(y, y_prob)\n    print(f\"ROC-AUC: {roc_auc:.4f}\")\n    fpr, tpr, _ = roc_curve(y, y_prob)\n    plt.figure(figsize=(8, 6))\n    plt.plot(fpr, tpr, label=f'{set_name} ROC Curve (AUC = {roc_auc:.4f})')\n    plt.plot([0, 1], [0, 1], 'k--', label='Random')\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title(f'ROC Curve - {set_name}')\n    plt.legend()\n    plt.grid(alpha=0.3)\n    plt.savefig(f'roc_curve_{set_name.lower()}.png')\n    plt.close()\n    \n    return roc_auc, y_prob\ntrain_auc, train_preds = evaluate_model(final_model, X_train_selected, y_train, \"Training\")\nval_auc, val_preds = evaluate_model(final_model, X_val_selected, y_val, \"Validation\")\ntest_auc, test_preds = evaluate_model(final_model, X_test_selected, y_test, \"Test\")\nplt.figure(figsize=(12, 8))\ncoefficients.sort_values('Coefficient').plot(x='Feature', y='Coefficient', kind='barh')\nplt.title('Feature Coefficients')\nplt.xlabel('Coefficient Value')\nplt.ylabel('Feature')\nplt.tight_layout()\nplt.savefig('feature_coefficients.png')\nplt.close()\nplt.figure(figsize=(10, 6))\nplt.hist(train_preds, alpha=0.5, bins=20, label='Train')\nplt.hist(val_preds, alpha=0.5, bins=20, label='Validation')\nplt.hist(test_preds, alpha=0.5, bins=20, label='Test')\nplt.title('Prediction Probability Distribution')\nplt.xlabel('Predicted Probability')\nplt.ylabel('Count')\nplt.legend()\nplt.savefig('prediction_distribution.png')\nplt.close()\nprint(\"\\nPrediction Summary:\")\nprint(f\"Train: Mean={np.mean(train_preds):.4f}, Min={np.min(train_preds):.4f}, Max={np.max(train_preds):.4f}\")\nprint(f\"Validation: Mean={np.mean(val_preds):.4f}, Min={np.min(val_preds):.4f}, Max={np.max(val_preds):.4f}\")\nprint(f\"Test: Mean={np.mean(test_preds):.4f}, Min={np.min(test_preds):.4f}, Max={np.max(test_preds):.4f}\")\ndf_test_copy = df_test.copy()\ndf_test_copy['predicted_prob'] = test_preds\ndf_test_copy['predicted_class'] = (test_preds >= 0.5).astype(int)\ndf_test_copy['correct'] = (df_test_copy['predicted_class'] == df_test_copy['target_binary']).astype(int)\nregion_accuracy = df_test_copy.groupby('RegionName')['correct'].mean().sort_values(ascending=False)\nprint(\"\\nTop 10 regions by prediction accuracy:\")\nprint(region_accuracy.head(10))\nprint(\"\\nBottom 10 regions by prediction accuracy:\")\nprint(region_accuracy.tail(10))\nregion_growth_prob = df_test_copy.groupby('RegionName')['predicted_prob'].mean().sort_values(ascending=False)\ntop_regions = region_growth_prob.head(10)\nplt.figure(figsize=(12, 8))\ntop_regions.plot(kind='bar')\nplt.title('Top 10 Regions by Predicted Growth Probability')\nplt.ylabel('Average Predicted Probability')\nplt.xticks(rotation=45, ha='right')\nplt.tight_layout()\nplt.savefig('top_regions_by_growth.png')\nplt.close()\n\nprint(\"\\nTop 10 regions by predicted growth probability:\")\nprint(top_regions)\nresults_df = pd.DataFrame({\n    'RegionName': df_test['RegionName'],\n    'date': df_test['date'],\n    'actual_binary': df_test['target_binary'],\n    'predicted_prob': test_preds,\n    'predicted_binary': (test_preds >= 0.5).astype(int)\n})\nresults_df.to_csv('housing_price_growth_predictions.csv', index=False)\n\nprint(\"\\nResults saved to housing_price_growth_predictions.csv\")\nprint(\"Model and visualizations have been saved.\")\nprint(\"\\nModel Training Complete!\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-15T13:29:51.615669Z","iopub.execute_input":"2025-04-15T13:29:51.616154Z","iopub.status.idle":"2025-04-15T13:29:58.815592Z","shell.execute_reply.started":"2025-04-15T13:29:51.616122Z","shell.execute_reply":"2025-04-15T13:29:58.814349Z"}},"outputs":[{"name":"stdout","text":"# Housing Price Growth Prediction Model\n## Approach #4: Improved Logistic Regression Model\nCreating temporal features...\nTrain set: 9690 rows, from 2007-01-31 to 2022-10-31\nValidation set: 306 rows, from 2022-11-30 to 2023-04-30\nTest set: 306 rows, from 2023-05-31 to 2023-10-31\n\nAvailable features: 24 out of 26\n\nPerforming feature selection...\n\nTop 15 most important features:\npct_change_1m: 0.1933\npct_change_3m: 0.1098\nROC_3m: 0.1002\nROC_6m: 0.0823\npct_change_6m: 0.0601\nPersonal_consumption_expenditure: 0.0503\nCPI_Rent: 0.0482\nCPI: 0.0468\ndisposable_income: 0.0463\nNASDAQ: 0.0401\nYear: 0.0287\nMortgage_rate: 0.0258\nUnemp_rate: 0.0214\nZHVI_3m_vol: 0.0146\npersonal_savings: 0.0132\n\nSelected 15 features from 77 total features\nSelected features: ['pct_change_1m', 'pct_change_3m', 'pct_change_6m', 'ZHVI_3m_vol', 'ROC_3m', 'ROC_6m', 'Mortgage_rate', 'CPI', 'CPI_Rent', 'Unemp_rate', 'NASDAQ', 'disposable_income', 'Personal_consumption_expenditure', 'personal_savings', 'Year']\n\nTraining logistic regression with cross-validation...\nC=0.001: Mean ROC-AUC: 0.9302\nC=0.01: Mean ROC-AUC: 0.9519\nC=0.1: Mean ROC-AUC: 0.9571\nC=1.0: Mean ROC-AUC: 0.9591\nC=10.0: Mean ROC-AUC: 0.9589\nC=100.0: Mean ROC-AUC: 0.9588\nBest C value: 1.0 with ROC-AUC: 0.9591\n\nTop positive coefficients:\n              Feature  Coefficient\n14               Year     4.015527\n1       pct_change_3m     1.280415\n4              ROC_3m     1.280415\n10             NASDAQ     1.000116\n13   personal_savings     0.302369\n2       pct_change_6m     0.169147\n5              ROC_6m     0.169147\n0       pct_change_1m     0.158257\n3         ZHVI_3m_vol     0.028156\n11  disposable_income    -0.033970\n\nTop negative coefficients:\n                             Feature  Coefficient\n2                      pct_change_6m     0.169147\n5                             ROC_6m     0.169147\n0                      pct_change_1m     0.158257\n3                        ZHVI_3m_vol     0.028156\n11                 disposable_income    -0.033970\n6                      Mortgage_rate    -0.568802\n9                         Unemp_rate    -1.097477\n7                                CPI    -1.209285\n8                           CPI_Rent    -1.562236\n12  Personal_consumption_expenditure    -2.588533\n\nTraining Performance:\n              precision    recall  f1-score   support\n\n           0       0.85      0.84      0.84      2862\n           1       0.93      0.94      0.94      6828\n\n    accuracy                           0.91      9690\n   macro avg       0.89      0.89      0.89      9690\nweighted avg       0.91      0.91      0.91      9690\n\nROC-AUC: 0.9578\n\nValidation Performance:\n              precision    recall  f1-score   support\n\n           0       0.46      1.00      0.63       141\n           1       1.00      0.01      0.01       165\n\n    accuracy                           0.46       306\n   macro avg       0.73      0.50      0.32       306\nweighted avg       0.75      0.46      0.30       306\n\nROC-AUC: 0.8542\n\nTest Performance:\n              precision    recall  f1-score   support\n\n           0       0.10      1.00      0.19        28\n           1       1.00      0.13      0.23       278\n\n    accuracy                           0.21       306\n   macro avg       0.55      0.57      0.21       306\nweighted avg       0.92      0.21      0.23       306\n\nROC-AUC: 0.9011\n\nPrediction Summary:\nTrain: Mean=0.7045, Min=0.0000, Max=1.0000\nValidation: Mean=0.0623, Min=0.0004, Max=0.5799\nTest: Mean=0.2631, Min=0.0088, Max=0.8283\n\nTop 10 regions by prediction accuracy:\nRegionName\nLA    1.000000\nCT    0.833333\nNH    0.833333\nME    0.833333\nMA    0.833333\nRI    0.666667\nNJ    0.666667\nCA    0.500000\nSD    0.500000\nOH    0.500000\nName: correct, dtype: float64\n\nBottom 10 regions by prediction accuracy:\nRegionName\nNE    0.0\nNC    0.0\nIA    0.0\nMO    0.0\nMI    0.0\nID    0.0\nMD    0.0\nIL    0.0\nIN    0.0\nWY    0.0\nName: correct, dtype: float64\n\nTop 10 regions by predicted growth probability:\nRegionName\nCT    0.714916\nME    0.609701\nNH    0.558084\nRI    0.553851\nMA    0.546476\nNJ    0.530337\nOH    0.439946\nIL    0.393645\nWI    0.392709\nCA    0.388666\nName: predicted_prob, dtype: float64\n\nResults saved to housing_price_growth_predictions.csv\nModel and visualizations have been saved.\n\nModel Training Complete!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x800 with 0 Axes>"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}